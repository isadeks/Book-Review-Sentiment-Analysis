{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Implement Your Machine Learning Project Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will implement the machine learning project plan you created in the written assignment. You will:\n",
    "\n",
    "1. Load your data set and save it to a Pandas DataFrame.\n",
    "2. Perform exploratory data analysis on your data to determine which feature engineering and data preparation techniques you will use.\n",
    "3. Prepare your data for your model and create features and a label.\n",
    "4. Fit your model to the training data and evaluate your model.\n",
    "5. Improve your model by performing model selection and/or feature selection techniques to find best model for your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "Before you get started, import a few packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load the Data Set\n",
    "\n",
    "\n",
    "You have chosen to work with one of four data sets.\n",
    "\n",
    "* The book review data set is located in file `bookReviewsData.csv`\n",
    "\n",
    "\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load your data using `pd.read_csv()` and save it to DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"bookReviewsData.csv\"\n",
    "df = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis\n",
    "\n",
    "The next step is to inspect and analyze your data set with your machine learning problem and project plan in mind. \n",
    "\n",
    "This step will help you determine data preparation and feature engineering techniques you will need to apply to your data to build a balanced modeling data set for your problem and model. These data preparation techniques may include:\n",
    "* addressing missingness, such as replacing missing values with means\n",
    "* renaming features and labels\n",
    "* finding and replacing outliers\n",
    "* performing winsorization if needed\n",
    "* performing one-hot encoding on categorical features\n",
    "* performing vectorization for an NLP problem\n",
    "* addressing class imbalance in your data sample to promote fair AI\n",
    "\n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. \n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980\n",
      "993\n"
     ]
    }
   ],
   "source": [
    "# Checking if Data is balanced\n",
    "print(df['Positive Review'].sum())\n",
    "print(len(df) - df['Positive Review'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I did not find this book very helpful. There i...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton's old friend and key Russia advisor pr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The novels in this series are not the escapist...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This book is as much about life as it is about...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have been slogging through this book for wee...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive Review\n",
       "0  I did not find this book very helpful. There i...            False\n",
       "1  Clinton's old friend and key Russia advisor pr...             True\n",
       "2  The novels in this series are not the escapist...             True\n",
       "3  This book is as much about life as it is about...             True\n",
       "4  I have been slogging through this book for wee...            False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect head of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980\n",
      "980\n"
     ]
    }
   ],
   "source": [
    "positive_samples = df[df['Positive Review'] == 1]\n",
    "negative_samples = df[df['Positive Review'] == 0]\n",
    "\n",
    "# Oversample the positive class\n",
    "oversampled_positive = positive_samples.sample(n=980, replace=True, random_state=123)\n",
    "\n",
    "# Undersample the negative class to match the size of the positive class\n",
    "undersampled_negative = negative_samples.sample(n=980, random_state=123)\n",
    "\n",
    "# Concatenate the oversampled positive class with the undersampled negative class\n",
    "df = pd.concat([oversampled_positive, undersampled_negative])\n",
    "\n",
    "# Shuffle the dataset to ensure randomness\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Checking if Data is balanced\n",
    "print(df['Positive Review'].sum())\n",
    "print(len(df) - df['Positive Review'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review             False\n",
       "Positive Review    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensuring no null values\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [did, not, find, this, book, very, helpful, th...\n",
       "1    [clinton, old, friend, and, key, russia, advis...\n",
       "2    [the, novels, in, this, series, are, not, the,...\n",
       "3    [this, book, is, as, much, about, life, as, it...\n",
       "4    [have, been, slogging, through, this, book, fo...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Positive Review']\n",
    "X = df['Review']\n",
    "\n",
    "# Transforming the text to features\n",
    "original_X = X\n",
    "X = X.apply(lambda row: gensim.utils.simple_preprocess(row))\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "483     [have, yet, to, use, an, actual, phrase, from,...\n",
       "760     [am, not, going, to, repeat, other, reviewers,...\n",
       "1491    [ve, read, many, books, on, meditation, and, w...\n",
       "593     [first, read, this, book, back, in, the, mid, ...\n",
       "1115    [had, chance, to, read, this, book, cover, to,...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.80, random_state=1234)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.Word2Vec(X_train,\n",
    "                                   vector_size=100,\n",
    "                                   window=5,\n",
    "                                   min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9476"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measure size of model\n",
    "len(word2vec_model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. You will:\n",
    "\n",
    "1. Prepare your data for your model and create features and a label.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features into training and testing set\n",
    "words = set(word2vec_model.wv.index_to_key)\n",
    "\n",
    "X_train = np.array([np.array([word2vec_model.wv[word] for word in words if word in training_example])\n",
    "                        for training_example in X_train], dtype=object)\n",
    "\n",
    "X_test = np.array([np.array([word2vec_model.wv[word] for word in words if word in training_example])\n",
    "                        for training_example in X_test], dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a consistent set of features per example\n",
    "X_train_feature_vector = []\n",
    "for w in X_train:\n",
    "    if w.size:\n",
    "        X_train_feature_vector.append(w.mean(axis=0))\n",
    "    else:\n",
    "        X_train_feature_vector.append(np.zeros(100, dtype=float))\n",
    "        \n",
    "X_test_feature_vector = []\n",
    "for w in X_test:\n",
    "    if w.size:\n",
    "        X_test_feature_vector.append(w.mean(axis=0))\n",
    "    else:\n",
    "        X_test_feature_vector.append(np.zeros(100, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1 | AUC on the test data: 0.6517\n",
      "Max Depth: 2 | AUC on the test data: 0.6678\n",
      "Max Depth: 4 | AUC on the test data: 0.7526\n",
      "Max Depth: 8 | AUC on the test data: 0.7916\n",
      "Max Depth: 16 | AUC on the test data: 0.7949\n",
      "Max Depth: 32 | AUC on the test data: 0.7949\n",
      "Max Depth: 64 | AUC on the test data: 0.7949\n",
      "Max Depth: 128 | AUC on the test data: 0.7949\n"
     ]
    }
   ],
   "source": [
    "roc_scores = []\n",
    "\n",
    "# Model Selection\n",
    "hyperparams = [2**n for n in range(0,8)]\n",
    "hyperparams\n",
    "best_md_score = 0\n",
    "\n",
    "for md in hyperparams:\n",
    "    \n",
    "    model = DecisionTreeClassifier(max_depth = md, min_samples_leaf = 40)\n",
    "\n",
    "    model.fit(X_train_feature_vector, y_train)\n",
    "    # 2. Make predictions on the transformed test data using the predict_proba() method and \n",
    "    # save the values of the second column\n",
    "    probability_predictions = model.predict_proba(X_test_feature_vector)[:,1]\n",
    "\n",
    "    # 3. Make predictions on the transformed test data using the predict() method \n",
    "    class_label_predictions = model.predict(X_test_feature_vector)\n",
    "\n",
    "    # 4. Compute the Area Under the ROC curve (AUC) for the test data. Note that this time we are using one \n",
    "    # function 'roc_auc_score()' to compute the auc rather than using both 'roc_curve()' and 'auc()' as we have \n",
    "    # done in the past\n",
    "    auc = roc_auc_score(y_test, probability_predictions)\n",
    "    print('Max Depth: {0} | AUC on the test data: {1:.4f}'.format(md,auc))\n",
    "    \n",
    "    best_md_score = max(best_md_score,auc)\n",
    "\n",
    "roc_scores.append(best_md_score) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 1e-10 | AUC on the test data: 0.6424\n",
      "C= 1e-09 | AUC on the test data: 0.6424\n",
      "C= 1e-08 | AUC on the test data: 0.6451\n",
      "C= 1e-07 | AUC on the test data: 0.6451\n",
      "C= 1e-06 | AUC on the test data: 0.6451\n",
      "C= 1e-05 | AUC on the test data: 0.6451\n",
      "C= 0.0001 | AUC on the test data: 0.6451\n",
      "C= 0.001 | AUC on the test data: 0.6459\n",
      "C= 0.01 | AUC on the test data: 0.6478\n",
      "C= 0.1 | AUC on the test data: 0.6625\n",
      "C= 1 | AUC on the test data: 0.7109\n",
      "C= 10 | AUC on the test data: 0.7576\n",
      "C= 100 | AUC on the test data: 0.7894\n",
      "C= 1000 | AUC on the test data: 0.8217\n",
      "C= 10000 | AUC on the test data: 0.8376\n",
      "C= 100000 | AUC on the test data: 0.8388\n",
      "C= 1000000 | AUC on the test data: 0.8396\n",
      "C= 10000000 | AUC on the test data: 0.8396\n",
      "C= 100000000 | AUC on the test data: 0.8393\n",
      "C= 1000000000 | AUC on the test data: 0.8392\n"
     ]
    }
   ],
   "source": [
    "hyperparams = [10**i for i in range(-10,10)]\n",
    "accuracy_scores = []\n",
    "\n",
    "best_C_score = 0\n",
    "\n",
    "for c in hyperparams:\n",
    "    \n",
    "    model = LogisticRegression(C=c, max_iter = 10000)\n",
    "    model.fit(X_train_feature_vector, y_train)\n",
    "    # 2. Make predictions on the transformed test data using the predict_proba() method and \n",
    "    # save the values of the second column\n",
    "    probability_predictions = model.predict_proba(X_test_feature_vector)[:,1]\n",
    "\n",
    "    # 3. Make predictions on the transformed test data using the predict() method \n",
    "    class_label_predictions = model.predict(X_test_feature_vector)\n",
    "\n",
    "    # 4. Compute the Area Under the ROC curve (AUC) for the test data. Note that this time we are using one \n",
    "    # function 'roc_auc_score()' to compute the auc rather than using both 'roc_curve()' and 'auc()' as we have \n",
    "    # done in the past\n",
    "    auc = roc_auc_score(y_test, probability_predictions)\n",
    "    print('C= {0} | AUC on the test data: {1:.4f}'.format(c,auc))\n",
    "    \n",
    "    best_C_score = max(best_C_score,auc)\n",
    "\n",
    "roc_scores.append(best_C_score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors= 1 | AUC on the test data: 0.9130\n",
      "Neighbors= 3 | AUC on the test data: 0.9035\n",
      "Neighbors= 5 | AUC on the test data: 0.8738\n",
      "Neighbors= 7 | AUC on the test data: 0.8379\n",
      "Neighbors= 9 | AUC on the test data: 0.8205\n",
      "Neighbors= 11 | AUC on the test data: 0.8004\n",
      "Neighbors= 13 | AUC on the test data: 0.7783\n",
      "Neighbors= 15 | AUC on the test data: 0.7700\n",
      "Neighbors= 17 | AUC on the test data: 0.7740\n",
      "Neighbors= 19 | AUC on the test data: 0.7741\n",
      "Neighbors= 21 | AUC on the test data: 0.7719\n",
      "Neighbors= 23 | AUC on the test data: 0.7602\n",
      "Neighbors= 25 | AUC on the test data: 0.7565\n",
      "Neighbors= 27 | AUC on the test data: 0.7572\n",
      "Neighbors= 29 | AUC on the test data: 0.7538\n",
      "Neighbors= 31 | AUC on the test data: 0.7499\n",
      "Neighbors= 33 | AUC on the test data: 0.7447\n",
      "Neighbors= 35 | AUC on the test data: 0.7491\n",
      "Neighbors= 37 | AUC on the test data: 0.7456\n",
      "Neighbors= 39 | AUC on the test data: 0.7460\n",
      "Neighbors= 41 | AUC on the test data: 0.7483\n",
      "Neighbors= 43 | AUC on the test data: 0.7537\n",
      "Neighbors= 45 | AUC on the test data: 0.7553\n",
      "Neighbors= 47 | AUC on the test data: 0.7516\n",
      "Neighbors= 49 | AUC on the test data: 0.7585\n"
     ]
    }
   ],
   "source": [
    "hyperparams = [n for n in range(1,50,2)]\n",
    "hyperparams\n",
    "best_k_score = 0\n",
    "\n",
    "for k in hyperparams:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train_feature_vector, y_train)\n",
    "    # 2. Make predictions on the transformed test data using the predict_proba() method and \n",
    "    # save the values of the second column\n",
    "    probability_predictions = model.predict_proba(X_test_feature_vector)[:,1]\n",
    "\n",
    "    # 3. Make predictions on the transformed test data using the predict() method \n",
    "    class_label_predictions = model.predict(X_test_feature_vector)\n",
    "\n",
    "    # 4. Compute the Area Under the ROC curve (AUC) for the test data. Note that this time we are using one \n",
    "    # function 'roc_auc_score()' to compute the auc rather than using both 'roc_curve()' and 'auc()' as we have \n",
    "    # done in the past\n",
    "    auc = roc_auc_score(y_test, probability_predictions)\n",
    "    print('Neighbors= {0} | AUC on the test data: {1:.4f}'.format(k,auc))\n",
    "    best_k_score = max(best_k_score,auc)\n",
    "\n",
    "roc_scores.append(best_k_score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['LR', 'DT', 'KNN']\n",
    "\n",
    "rg = np.arange(3)\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(rg, roc_scores, width, label=\"AUC\")\n",
    "\n",
    "# Adding labels on top of each bar\n",
    "for bar, score in zip(bars, roc_scores):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{score:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xticks(rg, labels)\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.ylim([0.5, 1])\n",
    "\n",
    "plt.title('Model Performance')\n",
    "plt.legend(loc='upper left', ncol=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
